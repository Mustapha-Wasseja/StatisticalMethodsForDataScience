{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Social Media Relationships with Ordinary Least Squares\n",
    "\n",
    "**Linear models** in the form of **ordinary least squares regression** can often be help with understanding relationships between variables. In this exercise you will analyze synthetic data which relates game players' characteristics to social media engagement. \n",
    "\n",
    "To start, execute the code in the cell below to import the packages you will need for this example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as nr\n",
    "from scipy.stats import truncnorm\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import pandas as pd\n",
    "\n",
    "## matplotlib with display of graphs inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in the cell below generates synthetic data with characteristics of game players and social media engagement. These variables are drawn from a truncated multivariate Normal distribution, with limits of 0.0 and 10.0. Execute this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create data set as multivariate Normal\n",
    "covariance = np.array([[1.0,0.7,0.7,0.0],\n",
    "                      [0.7,1.0,0.6,0.7],\n",
    "                      [0.7,0.6,1.0,0.2],\n",
    "                      [0.0,0.7,0.2,1.0]])\n",
    "effect_data = pd.DataFrame(nr.multivariate_normal(mean=[3.0,2.0,2.0,2.0], cov=covariance, size=500),\n",
    "                           columns=['Fan','TimePlaying','SocialMedia','GameFamiliarity'])\n",
    "\n",
    "## Truncate values to range 0.0 <= x <= 10.0\n",
    "effect_data[effect_data < 0.0] = 0.0\n",
    "effect_data[effect_data > 10.0] = 10.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in the cell below transforms the TimePlaying variable by squaring the values. This transformation gives the transformed variable a positive skew. The code also rounds the values to two digits. Execute this code and examine the resulting data frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fan</th>\n",
       "      <th>TimePlaying</th>\n",
       "      <th>SocialMedia</th>\n",
       "      <th>GameFamiliarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.45</td>\n",
       "      <td>2.41</td>\n",
       "      <td>2.46</td>\n",
       "      <td>1.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.36</td>\n",
       "      <td>4.80</td>\n",
       "      <td>1.52</td>\n",
       "      <td>1.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.15</td>\n",
       "      <td>2.22</td>\n",
       "      <td>1.45</td>\n",
       "      <td>2.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.83</td>\n",
       "      <td>2.04</td>\n",
       "      <td>2.86</td>\n",
       "      <td>2.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.18</td>\n",
       "      <td>2.64</td>\n",
       "      <td>2.57</td>\n",
       "      <td>2.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.21</td>\n",
       "      <td>11.54</td>\n",
       "      <td>3.40</td>\n",
       "      <td>4.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.80</td>\n",
       "      <td>4.74</td>\n",
       "      <td>2.53</td>\n",
       "      <td>1.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.70</td>\n",
       "      <td>1.42</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.26</td>\n",
       "      <td>9.61</td>\n",
       "      <td>3.46</td>\n",
       "      <td>2.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.15</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1.30</td>\n",
       "      <td>2.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.01</td>\n",
       "      <td>5.16</td>\n",
       "      <td>1.64</td>\n",
       "      <td>3.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.21</td>\n",
       "      <td>10.22</td>\n",
       "      <td>2.34</td>\n",
       "      <td>3.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.73</td>\n",
       "      <td>2.19</td>\n",
       "      <td>1.60</td>\n",
       "      <td>2.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.45</td>\n",
       "      <td>2.98</td>\n",
       "      <td>2.70</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.57</td>\n",
       "      <td>3.58</td>\n",
       "      <td>0.90</td>\n",
       "      <td>3.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3.47</td>\n",
       "      <td>6.47</td>\n",
       "      <td>1.74</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4.76</td>\n",
       "      <td>11.77</td>\n",
       "      <td>3.01</td>\n",
       "      <td>2.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.94</td>\n",
       "      <td>2.51</td>\n",
       "      <td>2.07</td>\n",
       "      <td>1.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3.64</td>\n",
       "      <td>6.64</td>\n",
       "      <td>1.81</td>\n",
       "      <td>2.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.49</td>\n",
       "      <td>6.89</td>\n",
       "      <td>1.46</td>\n",
       "      <td>3.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3.61</td>\n",
       "      <td>10.86</td>\n",
       "      <td>2.55</td>\n",
       "      <td>3.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2.40</td>\n",
       "      <td>2.40</td>\n",
       "      <td>1.58</td>\n",
       "      <td>1.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3.23</td>\n",
       "      <td>3.23</td>\n",
       "      <td>1.09</td>\n",
       "      <td>1.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5.81</td>\n",
       "      <td>11.85</td>\n",
       "      <td>4.29</td>\n",
       "      <td>1.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2.82</td>\n",
       "      <td>2.97</td>\n",
       "      <td>2.10</td>\n",
       "      <td>1.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3.23</td>\n",
       "      <td>3.69</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5.61</td>\n",
       "      <td>11.67</td>\n",
       "      <td>4.05</td>\n",
       "      <td>1.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.82</td>\n",
       "      <td>0.28</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.68</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4.04</td>\n",
       "      <td>16.98</td>\n",
       "      <td>1.65</td>\n",
       "      <td>4.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>2.80</td>\n",
       "      <td>5.28</td>\n",
       "      <td>3.23</td>\n",
       "      <td>2.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>2.25</td>\n",
       "      <td>0.58</td>\n",
       "      <td>1.35</td>\n",
       "      <td>1.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>4.53</td>\n",
       "      <td>11.08</td>\n",
       "      <td>2.06</td>\n",
       "      <td>2.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>2.11</td>\n",
       "      <td>3.23</td>\n",
       "      <td>2.62</td>\n",
       "      <td>2.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>2.41</td>\n",
       "      <td>1.16</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>4.93</td>\n",
       "      <td>9.95</td>\n",
       "      <td>4.07</td>\n",
       "      <td>2.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>2.90</td>\n",
       "      <td>6.22</td>\n",
       "      <td>1.89</td>\n",
       "      <td>2.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>2.40</td>\n",
       "      <td>1.35</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>3.67</td>\n",
       "      <td>5.90</td>\n",
       "      <td>2.85</td>\n",
       "      <td>2.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>3.66</td>\n",
       "      <td>1.62</td>\n",
       "      <td>1.48</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>2.24</td>\n",
       "      <td>4.13</td>\n",
       "      <td>1.06</td>\n",
       "      <td>2.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>3.29</td>\n",
       "      <td>13.39</td>\n",
       "      <td>1.78</td>\n",
       "      <td>4.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>2.75</td>\n",
       "      <td>5.55</td>\n",
       "      <td>2.57</td>\n",
       "      <td>2.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>1.78</td>\n",
       "      <td>1.22</td>\n",
       "      <td>1.06</td>\n",
       "      <td>1.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>4.44</td>\n",
       "      <td>9.17</td>\n",
       "      <td>2.95</td>\n",
       "      <td>2.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>2.89</td>\n",
       "      <td>3.67</td>\n",
       "      <td>2.67</td>\n",
       "      <td>2.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>3.37</td>\n",
       "      <td>9.37</td>\n",
       "      <td>2.23</td>\n",
       "      <td>3.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>1.68</td>\n",
       "      <td>3.85</td>\n",
       "      <td>0.55</td>\n",
       "      <td>3.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>4.89</td>\n",
       "      <td>12.85</td>\n",
       "      <td>4.20</td>\n",
       "      <td>2.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>1.51</td>\n",
       "      <td>3.21</td>\n",
       "      <td>0.97</td>\n",
       "      <td>3.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>3.81</td>\n",
       "      <td>8.31</td>\n",
       "      <td>2.07</td>\n",
       "      <td>2.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>3.37</td>\n",
       "      <td>4.49</td>\n",
       "      <td>2.28</td>\n",
       "      <td>1.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>2.71</td>\n",
       "      <td>0.92</td>\n",
       "      <td>2.04</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>2.67</td>\n",
       "      <td>2.54</td>\n",
       "      <td>2.42</td>\n",
       "      <td>1.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>3.45</td>\n",
       "      <td>4.60</td>\n",
       "      <td>2.30</td>\n",
       "      <td>1.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>3.54</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>2.65</td>\n",
       "      <td>5.43</td>\n",
       "      <td>2.34</td>\n",
       "      <td>2.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>4.37</td>\n",
       "      <td>11.87</td>\n",
       "      <td>3.06</td>\n",
       "      <td>2.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>2.55</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1.35</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>1.29</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Fan  TimePlaying  SocialMedia  GameFamiliarity\n",
       "0    2.45         2.41         2.46             1.92\n",
       "1    3.36         4.80         1.52             1.96\n",
       "2    2.15         2.22         1.45             2.05\n",
       "3    1.83         2.04         2.86             2.19\n",
       "4    2.18         2.64         2.57             2.56\n",
       "5    3.21        11.54         3.40             4.14\n",
       "6    3.80         4.74         2.53             1.16\n",
       "7    2.70         1.42         1.28             1.02\n",
       "8    4.26         9.61         3.46             2.03\n",
       "9    1.15         0.83         1.30             2.46\n",
       "10   2.01         5.16         1.64             3.65\n",
       "11   3.21        10.22         2.34             3.53\n",
       "12   1.73         2.19         1.60             2.73\n",
       "13   2.45         2.98         2.70             2.31\n",
       "14   1.57         3.58         0.90             3.22\n",
       "15   3.47         6.47         1.74             2.31\n",
       "16   4.76        11.77         3.01             2.51\n",
       "17   2.94         2.51         2.07             1.56\n",
       "18   3.64         6.64         1.81             2.05\n",
       "19   2.49         6.89         1.46             3.23\n",
       "20   3.61        10.86         2.55             3.52\n",
       "21   2.40         2.40         1.58             1.68\n",
       "22   3.23         3.23         1.09             1.20\n",
       "23   5.81        11.85         4.29             1.23\n",
       "24   2.82         2.97         2.10             1.74\n",
       "25   3.23         3.69         0.84             1.35\n",
       "26   5.61        11.67         4.05             1.33\n",
       "27   1.82         0.28         1.01             1.10\n",
       "28   1.68         0.98         0.27             1.41\n",
       "29   4.04        16.98         1.65             4.12\n",
       "..    ...          ...          ...              ...\n",
       "470  2.80         5.28         3.23             2.81\n",
       "471  2.25         0.58         1.35             1.18\n",
       "472  4.53        11.08         2.06             2.54\n",
       "473  2.11         3.23         2.62             2.93\n",
       "474  2.41         1.16         0.85             1.11\n",
       "475  4.93         9.95         4.07             2.08\n",
       "476  2.90         6.22         1.89             2.73\n",
       "477  2.40         1.35         1.02             0.89\n",
       "478  3.67         5.90         2.85             2.03\n",
       "479  3.66         1.62         1.48             0.21\n",
       "480  2.24         4.13         1.06             2.86\n",
       "481  3.29        13.39         1.78             4.05\n",
       "482  2.75         5.55         2.57             2.97\n",
       "483  1.78         1.22         1.06             1.93\n",
       "484  4.44         9.17         2.95             2.21\n",
       "485  2.89         3.67         2.67             2.20\n",
       "486  3.37         9.37         2.23             3.32\n",
       "487  1.68         3.85         0.55             3.06\n",
       "488  4.89        12.85         4.20             2.50\n",
       "489  1.51         3.21         0.97             3.06\n",
       "490  3.81         8.31         2.07             2.88\n",
       "491  3.37         4.49         2.28             1.61\n",
       "492  2.71         0.92         2.04             0.72\n",
       "493  2.67         2.54         2.42             1.89\n",
       "494  3.45         4.60         2.30             1.70\n",
       "495  3.54         1.06         0.14             0.00\n",
       "496  2.65         5.43         2.34             2.36\n",
       "497  4.37        11.87         3.06             2.63\n",
       "498  2.55         0.93         1.35             0.82\n",
       "499  1.29         0.08         0.91             1.67\n",
       "\n",
       "[500 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " ## Square the values of TimePlaying to give positive skew\n",
    "effect_data['TimePlaying'] = np.square(effect_data['TimePlaying'])\n",
    "\n",
    "## And round all values to 2 decimal places\n",
    "effect_data = effect_data.round(decimals=2)\n",
    "effect_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in the cell below finds a linear models SocialMedia engagement as a function of TimePlaying. Execute this code and examine the results.   \n",
    "\n",
    "> The code in the cell below uses the R style model formula. This modeling language was introduced in Chambers and Hastie, 1992, Statistical Models in S.     \n",
    "\n",
    "> For a good [**cheatsheet and summary of the R modeling language**](http://faculty.chicagobooth.edu/richard.hahn/teaching/formulanotation.pdf) look at the posting by Richard Hahn of the Chicago Booth School.    \n",
    "\n",
    "> Models are defined by an equation using the $\\sim$ symbol to mean modeled by. In summary, the variable to be modeled is always on the left. The relationship between the variable to be modeled on the right. This basic scheme can be written: \n",
    "\n",
    "$$dependent\\ variable\\sim indepenent\\ variables$$\n",
    "\n",
    "> For example, if the dependent variable (dv) is modeled by two independent variables (var1 and var2), with no interaction, the formula would be:\n",
    "$$dv \\sim var1 + var2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>SocialMedia</td>   <th>  R-squared:         </th> <td>   0.328</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.327</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   243.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 05 Jan 2020</td> <th>  Prob (F-statistic):</th> <td>6.23e-45</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>18:03:14</td>     <th>  Log-Likelihood:    </th> <td> -581.89</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   500</td>      <th>  AIC:               </th> <td>   1168.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   498</td>      <th>  BIC:               </th> <td>   1176.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>   <td>    1.3627</td> <td>    0.055</td> <td>   24.878</td> <td> 0.000</td> <td>    1.255</td> <td>    1.470</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TimePlaying</th> <td>    0.1330</td> <td>    0.009</td> <td>   15.594</td> <td> 0.000</td> <td>    0.116</td> <td>    0.150</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>10.639</td> <th>  Durbin-Watson:     </th> <td>   2.038</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.005</td> <th>  Jarque-Bera (JB):  </th> <td>   6.331</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.081</td> <th>  Prob(JB):          </th> <td>  0.0422</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.473</td> <th>  Cond. No.          </th> <td>    10.3</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:            SocialMedia   R-squared:                       0.328\n",
       "Model:                            OLS   Adj. R-squared:                  0.327\n",
       "Method:                 Least Squares   F-statistic:                     243.2\n",
       "Date:                Sun, 05 Jan 2020   Prob (F-statistic):           6.23e-45\n",
       "Time:                        18:03:14   Log-Likelihood:                -581.89\n",
       "No. Observations:                 500   AIC:                             1168.\n",
       "Df Residuals:                     498   BIC:                             1176.\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===============================================================================\n",
       "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------\n",
       "Intercept       1.3627      0.055     24.878      0.000       1.255       1.470\n",
       "TimePlaying     0.1330      0.009     15.594      0.000       0.116       0.150\n",
       "==============================================================================\n",
       "Omnibus:                       10.639   Durbin-Watson:                   2.038\n",
       "Prob(Omnibus):                  0.005   Jarque-Bera (JB):                6.331\n",
       "Skew:                           0.081   Prob(JB):                       0.0422\n",
       "Kurtosis:                       2.473   Cond. No.                         10.3\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "social_time_model = smf.ols(formula = 'SocialMedia ~ TimePlaying', data=effect_data).fit()\n",
    "social_time_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The summary of the ordinary least squares model contains quite a lot information. We will only focus on a few of these values:    \n",
    "- The value of the coefficient is an estimate of the **effect size**. In this case the effect being measured is TimePlaying. \n",
    "- The confidence interval of the coefficient value which indicates the range of likely values for the effect size. It is important to keep in mind that any estimated effect size is uncertain and not exact. \n",
    "- The adjusted R-squared value which is the ratio of the ratio of the variance of the residuals of from the fitted model and the variance of the dependent variable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "> #### Summary of R-Squared\n",
    "\n",
    "> - **R squared or $R^2$**, also known as the **coefficient of determination**,  \n",
    "$$R^2 = 1 - \\frac{SS_{res}}{SS_{tot}}$$  \n",
    "where,   \n",
    "$SS_{res} = \\sum_{i=1}^N r_i^2$, or the sum of the squared residuals,   \n",
    "$SS_{tot} = \\sum_{i=1}^N y_i^2$, or the sum of the squared label values.  \n",
    "\n",
    "> In other words, $R^2$ is  measure of the reduction in sum of squared values between the raw label values and the residuals. If the model has not reduced the sum of squares of the labels (a useless model!), $R^2 = 0$. On the other hand, if the model fits the data perfectly so all $r_i = 0$, then $R^2 = 1$. \n",
    "\n",
    "> - **Adjusted R squared or $R^2_{adj}$** is $R^2$ adjusted for degrees of freedom in the model,\n",
    "$$R^2_{adj} = 1 - \\frac{var(r)}{var(y)} = 1 - \\frac{\\frac{SS_{res}}{(n - p -1)}}{\\frac{SS_{tot}}{(n-1)}}$$  \n",
    "where,   \n",
    "$var(r) = $ the variance of the residuals,   \n",
    "$var(y) = $ the variance of the labels,\n",
    "$n = $ the number of samples or cases,\n",
    "$p = $ number of model parameters.  \n",
    "\n",
    "> The interpretation of $R^2_{adj}$ is the same as $R^2$. In many cases there will be little difference. However if the number of parameters is significant with respect to the number of cases, $R^2$ will give an overly optimistic measure of model performance. In general, the difference between $R^2_{adj}$ and $R^2$ becomes less significant as the number of cases $n$ grows. However, even for 'big data' models there can be a significant difference if there are a large number of model parameters.   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a next step in the analysis we will add another variable to the model, Fan. Execute the code in the cell below and examine the summary of the new model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>SocialMedia</td>   <th>  R-squared:         </th> <td>   0.478</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.476</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   227.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 05 Jan 2020</td> <th>  Prob (F-statistic):</th> <td>6.96e-71</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>18:03:15</td>     <th>  Log-Likelihood:    </th> <td> -518.78</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   500</td>      <th>  AIC:               </th> <td>   1044.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   497</td>      <th>  BIC:               </th> <td>   1056.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>   <td>    0.2901</td> <td>    0.102</td> <td>    2.846</td> <td> 0.005</td> <td>    0.090</td> <td>    0.490</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TimePlaying</th> <td>    0.0463</td> <td>    0.010</td> <td>    4.427</td> <td> 0.000</td> <td>    0.026</td> <td>    0.067</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fan</th>         <td>    0.4975</td> <td>    0.042</td> <td>   11.947</td> <td> 0.000</td> <td>    0.416</td> <td>    0.579</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 4.342</td> <th>  Durbin-Watson:     </th> <td>   1.947</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.114</td> <th>  Jarque-Bera (JB):  </th> <td>   3.701</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.125</td> <th>  Prob(JB):          </th> <td>   0.157</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.661</td> <th>  Cond. No.          </th> <td>    25.1</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:            SocialMedia   R-squared:                       0.478\n",
       "Model:                            OLS   Adj. R-squared:                  0.476\n",
       "Method:                 Least Squares   F-statistic:                     227.5\n",
       "Date:                Sun, 05 Jan 2020   Prob (F-statistic):           6.96e-71\n",
       "Time:                        18:03:15   Log-Likelihood:                -518.78\n",
       "No. Observations:                 500   AIC:                             1044.\n",
       "Df Residuals:                     497   BIC:                             1056.\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===============================================================================\n",
       "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------\n",
       "Intercept       0.2901      0.102      2.846      0.005       0.090       0.490\n",
       "TimePlaying     0.0463      0.010      4.427      0.000       0.026       0.067\n",
       "Fan             0.4975      0.042     11.947      0.000       0.416       0.579\n",
       "==============================================================================\n",
       "Omnibus:                        4.342   Durbin-Watson:                   1.947\n",
       "Prob(Omnibus):                  0.114   Jarque-Bera (JB):                3.701\n",
       "Skew:                           0.125   Prob(JB):                        0.157\n",
       "Kurtosis:                       2.661   Cond. No.                         25.1\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "social_time_fan_model = smf.ols(formula='SocialMedia ~ TimePlaying + Fan', data=effect_data).fit()\n",
    "social_time_fan_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice two changes between the first model and the model using two variables:\n",
    "- The coefficient (effect) value for the variable Fan is large and the effect for TimePlaying is now quite small. \n",
    "- The adjusted R-squared value is larger indicating this model explains more of the variance of the data.    \n",
    "\n",
    "Another possibility is to model social media engagement by TimePlaying and GameFamiliarity. Execute the code in the cell below, examine the results, and compare them to the previous models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>SocialMedia</td>   <th>  R-squared:         </th> <td>   0.366</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.363</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   143.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 05 Jan 2020</td> <th>  Prob (F-statistic):</th> <td>6.65e-50</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>18:03:15</td>     <th>  Log-Likelihood:    </th> <td> -567.38</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   500</td>      <th>  AIC:               </th> <td>   1141.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   497</td>      <th>  BIC:               </th> <td>   1153.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>       <td>    1.6885</td> <td>    0.080</td> <td>   21.089</td> <td> 0.000</td> <td>    1.531</td> <td>    1.846</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TimePlaying</th>     <td>    0.1683</td> <td>    0.011</td> <td>   15.993</td> <td> 0.000</td> <td>    0.148</td> <td>    0.189</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>GameFamiliarity</th> <td>   -0.2492</td> <td>    0.046</td> <td>   -5.450</td> <td> 0.000</td> <td>   -0.339</td> <td>   -0.159</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 4.621</td> <th>  Durbin-Watson:     </th> <td>   2.020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.099</td> <th>  Jarque-Bera (JB):  </th> <td>   3.360</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.038</td> <th>  Prob(JB):          </th> <td>   0.186</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.606</td> <th>  Cond. No.          </th> <td>    17.6</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:            SocialMedia   R-squared:                       0.366\n",
       "Model:                            OLS   Adj. R-squared:                  0.363\n",
       "Method:                 Least Squares   F-statistic:                     143.4\n",
       "Date:                Sun, 05 Jan 2020   Prob (F-statistic):           6.65e-50\n",
       "Time:                        18:03:15   Log-Likelihood:                -567.38\n",
       "No. Observations:                 500   AIC:                             1141.\n",
       "Df Residuals:                     497   BIC:                             1153.\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===================================================================================\n",
       "                      coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------\n",
       "Intercept           1.6885      0.080     21.089      0.000       1.531       1.846\n",
       "TimePlaying         0.1683      0.011     15.993      0.000       0.148       0.189\n",
       "GameFamiliarity    -0.2492      0.046     -5.450      0.000      -0.339      -0.159\n",
       "==============================================================================\n",
       "Omnibus:                        4.621   Durbin-Watson:                   2.020\n",
       "Prob(Omnibus):                  0.099   Jarque-Bera (JB):                3.360\n",
       "Skew:                           0.038   Prob(JB):                        0.186\n",
       "Kurtosis:                       2.606   Cond. No.                         17.6\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "social_time_familarity_model = smf.ols(formula='SocialMedia ~ TimePlaying + GameFamiliarity', data=effect_data).fit()\n",
    "social_time_familarity_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The effect sizes (coefficient values) are smaller in magnitude as is the R-squared value. Notice also that the sign of the GameFamiliarity effect is now negative. Given these results, we say that GameFamiliarity is a **confounding effect**. In other words, adding GameFamiliarity confounds, or masks the other effects, but is not explanitory. \n",
    "\n",
    "Given the above analysis, it seems that Fan is the variable that best explains social media engagement. This idea is easy to test, by creating a linear model of social media engagement as a function of Fan. Execute the code in the cell below to compute the model and display the summary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>SocialMedia</td>   <th>  R-squared:         </th> <td>   0.457</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.456</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   419.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 05 Jan 2020</td> <th>  Prob (F-statistic):</th> <td>4.04e-68</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>18:03:15</td>     <th>  Log-Likelihood:    </th> <td> -528.45</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   500</td>      <th>  AIC:               </th> <td>   1061.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   498</td>      <th>  BIC:               </th> <td>   1069.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    0.1333</td> <td>    0.097</td> <td>    1.369</td> <td> 0.172</td> <td>   -0.058</td> <td>    0.325</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fan</th>       <td>    0.6254</td> <td>    0.031</td> <td>   20.489</td> <td> 0.000</td> <td>    0.565</td> <td>    0.685</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 3.005</td> <th>  Durbin-Watson:     </th> <td>   1.923</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.223</td> <th>  Jarque-Bera (JB):  </th> <td>   3.045</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.164</td> <th>  Prob(JB):          </th> <td>   0.218</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.802</td> <th>  Cond. No.          </th> <td>    10.8</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:            SocialMedia   R-squared:                       0.457\n",
       "Model:                            OLS   Adj. R-squared:                  0.456\n",
       "Method:                 Least Squares   F-statistic:                     419.8\n",
       "Date:                Sun, 05 Jan 2020   Prob (F-statistic):           4.04e-68\n",
       "Time:                        18:03:15   Log-Likelihood:                -528.45\n",
       "No. Observations:                 500   AIC:                             1061.\n",
       "Df Residuals:                     498   BIC:                             1069.\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      0.1333      0.097      1.369      0.172      -0.058       0.325\n",
       "Fan            0.6254      0.031     20.489      0.000       0.565       0.685\n",
       "==============================================================================\n",
       "Omnibus:                        3.005   Durbin-Watson:                   1.923\n",
       "Prob(Omnibus):                  0.223   Jarque-Bera (JB):                3.045\n",
       "Skew:                           0.164   Prob(JB):                        0.218\n",
       "Kurtosis:                       2.802   Cond. No.                         10.8\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "social_fan_model = smf.ols(formula='SocialMedia ~ Fan', data=effect_data).fit()\n",
    "social_fan_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the following points about this model:\n",
    "- The effect size for Fan is large relative to effect sizes in other models.  \n",
    "- The R-squared value is nearly as large as the best previous model, indicating that the Fan variable has good explanatory power. \n",
    "\n",
    "From this analysis, what can you conclude about the relationship between Fan and TimePlaying and SocialMedia. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Copyright 2020, Stephen F Elston. All rights reserved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
